id,train_error_latitude,valid_error_latitude,train_error_longitude,valid_error_longitude,train_error,valid_error,test_error_public,description
1,0.6267,0.6371,0.9431,0.9317,0.7849,0.7844,0.7106,"Baseline, just encoding (Multilingual Universal Sentence Encoder V4) and linear stacking on level one with LGBM Meta"
2,0.3212,0.4978,0.3846,0.6214,0.3529,0.5596,0.5333,TfidfVectorizer + Level 1 -> LGBM Added + Meta XGB
3,0.3471,0.4881,0.2858,0.5931,0.31645,0.5406,0.5152,Same + Level 1: SVR + RF + ExtraTrees
4,0.2674,0.4906,0.3275,0.6008,0.29745,0.5457,0.5264,Added Lemmatization and German Stopwords
5,0.2377,0.4955,0.2642,0.6063,0.25095,0.5509,0.5379,Added Encodings (USE v4) to standard input
6,0.2607,0.4741,0.3086,0.5822,0.2847,0.5281,0.5144,"ngram_range -> (1, 5) and analyzer = 'char_wb'"
7,0.2394,0.4734,0.2972,0.5706,0.2683,0.5221,0.5181,"removed all emojis, ngram_range -> (1, 7) and analyzer = 'char_wb'"
8,0,0.4644,0,0.5644,0,0.5144,0.5002,25 * Ensamble Forrest Models + XGB Meta... Baseline 
9,0,0.4531,0,0.5425,0,0.4978,0.4911,Replace XGB with HistGradientBoostingRegressor as meta-learner
10,0,0.4475,0,0.5373,0,0.4924,0.4845,"Stacking SVC, RF, XGB with HistGradientBoostingRegressor + StandardScaler for SVC"
11,0,0.4435,0,0.5299,0,0.4867,0.4732,"Adding 15 level one learners on original data for variance, baseline"
12,0,Nan,0,Nan,0,Nan,0.4723,Bayesian Optimization Mean Stage 1
13,0,0.4422,0,0.5254,0,0.4838,0.4706,"Up to 57 estimators to level one, and separated level two with 5 SVR, 4 Hist and VotingRegressor as head"
14,0,0.4412,0,0.5247,0,0.4829,0.4715,"5 SVR, 4 Hist, 5 Cats, 1 RF, 1 BaggingNuSVR and VotingRegressor as head + finetunning"
15,0,0.4411,0,0.5245,0,0.4828,0.4711,Bayesian Optimization for parameters
16,0,Nan,0,Nan,0,Nan,0.4705,Bayesian Optimization Mean Stage 2
